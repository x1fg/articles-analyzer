Статья представляет TokenRing, эффективную параллельную архитектуру для работы с языковыми моделями с бесконечным контекстом (LLM). Основное внимание уделяется использованию двунаправленной коммуникации для улучшения параллелизма и производительности. Авторы предлагают новый подход, который позволяет моделям эффективно обрабатывать длинные последовательности данных, обеспечивая при этом высокую скорость вычислений. TokenRing использует кольцевую топологию для распределения задач между узлами, что позволяет минимизировать задержки и улучшить масштабируемость. Экспериментальные результаты демонстрируют значительное увеличение производительности по сравнению с традиционными методами, что делает TokenRing перспективным решением для работы с LLM в задачах, требующих обработки больших объемов данных.