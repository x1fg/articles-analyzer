Статья посвящена улучшению методов симуляции квантовых систем, описываемых линбладовскими уравнениями, которые учитывают как унитарную динамику, так и взаимодействие с окружающей средой. Авторы представляют новый подход, который позволяет значительно уменьшить глубину квантовых схем, необходимых для этой симуляции. Они используют технику, основанную на разложении времени эволюции на более короткие интервалы, что позволяет экспоненциально сократить количество требуемых квантовых гейтов. Это достижение имеет важное значение для практической реализации квантовых симуляций на существующих и будущих квантовых компьютерах, так как уменьшенная глубина схемы приводит к меньшему количеству ошибок и более эффективному использованию квантовых ресурсов.