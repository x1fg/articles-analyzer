Статья представляет метод под названием DoTA (Weight-Decomposed Tensor Adaptation), который предназначен для адаптации больших языковых моделей. Подход DoTA заключается в разложении весов модели на тензоры, что позволяет более эффективно адаптировать модель к новым задачам с меньшими затратами памяти и вычислительных ресурсов. Авторы показывают, что их метод позволяет достичь высокой производительности на различных задачах, сохраняя при этом компактность модели. В исследовании проведены эксперименты, которые демонстрируют преимущества DoTA по сравнению с традиционными методами адаптации весов, такими как полная дообучаемость и адаптация через слои.