Статья посвящена управлению различиями между доменами в больших языковых моделях (LLM) для задач классификации жанров и обнаружения сгенерированного текста. Авторы анализируют проблемы, возникающие при применении LLM к текстам, которые отличаются от тех, на которых модель была обучена, что может приводить к снижению точности. Они предлагают методы для минимизации таких "разрывов" между доменами, улучшая адаптацию моделей к новым жанрам и повышая их способность различать человеческий и машинный текст. В статье представлены экспериментальные результаты, демонстрирующие эффективность предложенных подходов и их влияние на производительность LLM в задачах классификации и детекции.