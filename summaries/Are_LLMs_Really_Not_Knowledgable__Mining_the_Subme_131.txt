Статья "Are LLMs Really Not Knowledgeable? Mining the Submerged Knowledge in LLMs' Memory" исследует вопрос о том, насколько большие языковые модели (LLMs) действительно обладают знаниями. Авторы рассматривают предположение, что LLMs могут казаться недостаточно знающими из-за ограничений методов извлечения информации, а не из-за отсутствия знаний в самих моделях. В работе предлагается методика для извлечения «погружённых» знаний из памяти LLMs, что позволяет выявить более глубокие уровни информации, хранящейся в моделях. Проведённые эксперименты показывают, что LLMs обладают более широкими и глубокими знаниями, чем считалось ранее, но эти знания могут быть скрыты за пределами традиционных методов извлечения. Таким образом, статья способствует лучшему пониманию возможностей и ограничений LLMs в контексте их познавательных способностей.