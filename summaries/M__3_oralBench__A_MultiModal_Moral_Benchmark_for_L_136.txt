Статья "M$^3$oralBench: A MultiModal Moral Benchmark for LVLMs" представляет собой исследование, направленное на оценку моральных аспектов больших языковых моделей (LVLMs) в мультимодальном контексте. Авторы вводят новый бенчмарк M$^3$oralBench, который позволяет тестировать и сравнивать модели с точки зрения их способности принимать моральные решения и оценивать этические аспекты различных сценариев, представленных как в текстовой, так и в визуальной формах.

Основная цель работы заключается в создании инструмента, который поможет понять, как LVLMs справляются с моральными дилеммами и могут ли они быть использованы в приложениях, требующих этических суждений. Бенчмарк включает в себя разнообразные задачи и сценарии, которые требуют от моделей учета моральных принципов и норм.

Авторы также проводят эксперименты с различными существующими LVLMs, используя M$^3$oralBench, и анализируют их производительность. Выводы исследования подчеркивают как успехи, так и ограничения нынешних моделей в понимании и применении моральных принципов, что открывает путь для будущих улучшений в этой области.