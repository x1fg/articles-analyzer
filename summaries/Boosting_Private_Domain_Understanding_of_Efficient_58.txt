Статья посвящена разработке новой фреймворк для оптимизации подсказок (prompt optimization) в многоязычных языковых моделях (MLLMs), который не требует настройки (tuning-free), адаптивен и универсален. Авторы стремятся улучшить понимание моделей в приватных доменах, что позволяет более эффективно использовать MLLMs в специфических контекстах. Предложенный метод обеспечивает автоматическую настройку подсказок для улучшения производительности модели без необходимости в ручной калибровке. Это делает процесс адаптации моделей более простым и доступным, способствуя их более широкому применению в различных специализированных областях.