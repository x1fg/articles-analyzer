Статья "Can Large Language Models Adapt to Other Agents In-Context?" исследует возможность больших языковых моделей (LLMs) адаптироваться к взаимодействию с другими агентами в процессе выполнения задач. Авторы изучают, насколько эффективно LLMs могут приспосабливаться к поведению и стратегиям других агентов, используя ограниченную информацию и контекст в реальном времени. Основное внимание в работе уделяется анализу способности LLMs к обучению в процессе выполнения задач (in-context learning) и их гибкости в изменении стратегии на основе наблюдаемого поведения других агентов. Результаты исследования показывают, что, хотя LLMs обладают определенной способностью к адаптации, их эффективность сильно зависит от сложности задачи и доступного контекста. Авторы также обсуждают потенциальные направления для улучшения адаптационных способностей LLMs, включая разработку новых архитектур и методов обучения.