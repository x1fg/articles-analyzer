import requests
import xml.etree.ElementTree as ET
from datetime import datetime, timedelta
from src.database.models import Article, SessionLocal

class ArxivParser:
    def __init__(self, queries, max_results=50, timeout=10):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞ arXiv.
        """
        self.queries = queries
        self.max_results = max_results
        self.timeout = timeout
        self.base_url = 'http://export.arxiv.org/api/query'
        self.one_month_ago = datetime.now() - timedelta(days=30)

    def fetch_articles(self, query):
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å—Ç–∞—Ç—å–∏ –ø–æ –∑–∞–ø—Ä–æ—Å—É —Å arXiv API.
        """
        params = {
            'search_query': query,
            'start': 0,
            'max_results': self.max_results,
            'sortBy': 'submittedDate',
            'sortOrder': 'descending'
        }
        try:
            response = requests.get(self.base_url, params=params, timeout=self.timeout)
            if response.status_code != 200:
                print(f"–û—à–∏–±–∫–∞ API: {response.status_code}")
                return []
        except requests.exceptions.RequestException as e:
            print(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e}")
            return []

        root = ET.fromstring(response.content)
        articles = []
        for entry in root.findall('{http://www.w3.org/2005/Atom}entry'):
            title = entry.find('{http://www.w3.org/2005/Atom}title').text
            published = entry.find('{http://www.w3.org/2005/Atom}published').text
            link = entry.find('{http://www.w3.org/2005/Atom}link[@type="application/pdf"]')
            pdf_url = link.attrib['href'] if link is not None else None
            articles.append({
                'title': title.strip(),
                'published_date': published,
                'pdf_url': pdf_url
            })
        return articles

    def filter_recent_articles(self, articles):
        """
        –§–∏–ª—å—Ç—Ä—É–µ—Ç —Å—Ç–∞—Ç—å–∏, –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–µ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π –º–µ—Å—è—Ü.
        """
        return [
            article for article in articles
            if datetime.strptime(article['published_date'], '%Y-%m-%dT%H:%M:%SZ') >= self.one_month_ago
        ]

    def save_articles_to_db(self, articles):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å—Ç–∞—Ç—å–∏ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö.
        """
        session = SessionLocal()
        try:
            for article in articles:
                if not session.query(Article).filter(Article.pdf_url == article['pdf_url']).first():
                    new_article = Article(
                        title=article['title'],
                        published_date=datetime.strptime(article['published_date'], '%Y-%m-%dT%H:%M:%SZ'),
                        pdf_url=article['pdf_url']
                    )
                    session.add(new_article)
                    print(f"–°—Ç–∞—Ç—å—è –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ –±–∞–∑—É: {article['title']}")
            session.commit()
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")
        finally:
            session.close()

    def run(self):
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø–∞—Ä—Å–∏–Ω–≥–∞.
        """
        for query in self.queries:
            print(f"\nüîç –ü–æ–∏—Å–∫ —Å—Ç–∞—Ç–µ–π –ø–æ –∑–∞–ø—Ä–æ—Å—É: {query}")
            articles = self.fetch_articles(query)
            recent_articles = self.filter_recent_articles(articles)
            self.save_articles_to_db(recent_articles)